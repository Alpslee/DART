<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Comparing Human-Centric and Robot-Centric Sample Efficiency for Robot Deep Learning from Demonstrations by BerkeleyAutomation</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/BerkeleyAutomation/DART">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/BerkeleyAutomation/DART/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/BerkeleyAutomation/DART/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1></h1>
          <p></p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/BerkeleyAutomation">BerkeleyAutomation</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h3>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>

<p>
One approach to Imitation Learning is  Behavior Cloning, in which a robot observes a supervisor and infers a control policy. A known problem with this ``off-policy" approach is that the robot's errors compound when drifting away from the supervisor's demonstrations.  On-policy, techniques alleviate this by iteratively collecting corrective actions for the current robot policy. However, these techniques can be tedious for human supervisors, add significant computation burden, and may visit dangerous states during training.  We propose an off-policy approach that \emph{injects noise} into the supervisor's policy while demonstrating. This forces the supervisor to demonstrate how to recover from errors. We propose a new algorithm, DART (Disturbances for Augmenting Robot Trajectories), that collects demonstrations with injected noise, and optimizes the noise level to approximate the error of the robot's trained policy during data collection.  We compare DART with DAgger and Behavior Cloning in two domains: in simulation with an algorithmic supervisor on the MuJoCo  tasks (Walker, Humanoid, Hopper, Half-Cheetah) and in physical experiments with human supervisors training a Toyota HSR robot to perform grasping in clutter.  For high dimensional tasks like Humanoid, DART can be up to $3x$ faster in computation time and only decreases the supervisor's cumulative reward by $5\%$ during training, whereas DAgger executes policies that have $80\%$ less cumulative reward than the supervisor.  On the grasping in clutter task, DART obtains on average a $62\%$ performance increase over Behavior Cloning.  
</p>

<h3>
    <a id="files" class="anchor" href="#files" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Paper</h3>
    <ul>
        <li><a href='https://arxiv.org/abs/1610.00850'>Arxiv</a></li>        
        <li><a href='https://github.com/BerkeleyAutomation/lfd_icra2017/raw/gh-pages/files/icra2017.pdf'>Extended version</a></li>
    </ul>

<h3>
    <a id="video" class="anchor" href="#video" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Video of Singulation Task</h3>
<div align="center">
<iframe width="560" height="315" src="https://youtu.be/LfMD69llesg" frameborder="0" allowfullscreen></iframe>
</div>


<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p> <a href="https://people.eecs.berkeley.edu/~laskeymd/">Michael Laskey</a>, Jonathan Lee, Roy Fox, Anca Dragan, Ken Goldberg</p>

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support or Contact</h3>

<p>Please contact Michael Laskey (laskeymd AT berkeley DOT edu) for further information.</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
